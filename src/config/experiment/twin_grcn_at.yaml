# @package _global_
experiment_name: "twin_grcn_at"
shared_agent : True
early_stopping: True
add_other_agents_targets_to_resource: False
add_x_y_position_of_resource: True
observation: FullObservationGRCNTwin
shared_reward: False
create_observation_between_steps: False
replay_size : 100000
model_optimizer: { optimizer: RMSprop ,lr: 0.002, alpha: 0.99}
#model_optimizer: { optimizer: Adam ,lr: 0.0012}
update_target_every : 3125 # 125 #3125
slow_target_fraction : 1.0
train_every : 32
batch_size : 256
max_gradient_norm : 2.0
train_steps: 1
reward_clipping: tanh
prioritized_replay: False

path_to_model: /home/wiss/strauss/projects/mtop/src/multirun/standard/twin_grcn_at/2/2022-03-04/12-17-48/+experiment=twin_grcn_at,agent/model@model=grcn_twin_att_big,area=downtown,model.grcn.normalization_type=softmax,model_optimizer.lr=0.0001,number_of_environment_steps=50000000,replay_size=250000,update_target_every=5000/wandb/run-20220304_122029-3q7jp5ic/../../models

trainer: ParallelSequentialAsyncResetTrainer
number_of_parallel_envs: 8

eval_every : 1600
evaluation_episodes: 1
save_every : 1600

epsilon_initial: 1.0 #number of steps until the epsilon decay starts
epsilon_min: 0.01 #minimum value of epsilon (e.g. 0.01)
epsilon_decay_start: 5000 #number of steps until the epsilon decay starts
steps_till_min_epsilon: 1500000 #steps until the minimum epsilon value should be reached (e.g. 200.000)
epsilon_decay: exp #exp or linear

defaults:
  - override /agent: ddqn
  - override /agent/model@model: grcn_twin_att